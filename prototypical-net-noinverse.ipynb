{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Learning With Prototypical Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:656: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:656: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "from preprocessing import read_images\n",
    "from prototypicalNet import PrototypicalNet, train_step, test_step, load_weights\n",
    "tqdm.pandas(desc=\"my bar!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading and Augmentation\n",
    "The Omniglot data set is designed for developing more human-like learning algorithms. It contains 1623 different handwritten characters from 50 different alphabets. Then to increase the number of classes, all the images are rotated by 90, 180 and 270 degrees and each rotation resulted in one more class. Hence the total count of classes reached to 6492(1623 * 4) classes. We split images of 4200 classes to training data and the rest went to test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading background images\n",
      "(77120, 28, 28, 3)\n",
      "(77120,)\n"
     ]
    }
   ],
   "source": [
    "# Reading the data\n",
    "print(\"Reading background images\")\n",
    "trainx, trainy = read_images(r'D:\\_hackerreborn\\Prototypical-Networks\\input\\omniglot\\images_background')\n",
    "print(trainx.shape)\n",
    "print(trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if GPU is available\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "# Converting input to pytorch Tensor\n",
    "trainx = torch.from_numpy(trainx).float()\n",
    "\n",
    "if use_gpu:\n",
    "    trainx = trainx.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([77120, 28, 28, 3]), (77120,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx.shape, trainy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import trange\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Image2Vector CNN which takes image of dimension (28x28x3) and return column vector length 64\n",
    "    \"\"\"\n",
    "    def sub_block(self, in_channels, out_channels=64, kernel_size=3):\n",
    "        block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=1),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.MaxPool2d(kernel_size=2)\n",
    "                )\n",
    "        return block\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.convnet1 = self.sub_block(3)\n",
    "        self.convnet2 = self.sub_block(64)\n",
    "        self.convnet3 = self.sub_block(64)\n",
    "        self.convnet4 = self.sub_block(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convnet1(x)\n",
    "        x = self.convnet2(x)\n",
    "        x = self.convnet3(x)\n",
    "        x = self.convnet4(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypicalNet(nn.Module):\n",
    "    def __init__(self, use_gpu=False):\n",
    "        super(PrototypicalNet, self).__init__()\n",
    "        self.f = Net()\n",
    "        self.gpu = use_gpu\n",
    "        if self.gpu:\n",
    "            self.f = self.f.cuda()\n",
    "    \n",
    "    def forward(self, datax, datay, Ns,Nc, Nq, total_classes):\n",
    "        \"\"\"\n",
    "        Implementation of one episode in Prototypical Net\n",
    "        datax: Training images\n",
    "        datay: Corresponding labels of datax\n",
    "        Nc: Number  of classes per episode\n",
    "        Ns: Number of support data per class\n",
    "        Nq:  Number of query data per class\n",
    "        total_classes: Total classes in training set\n",
    "        \"\"\"\n",
    "        k = total_classes.shape[0]\n",
    "        K = np.random.choice(total_classes, Nc, replace=False)\n",
    "        Query_x = torch.Tensor()\n",
    "        if(self.gpu):\n",
    "            Query_x = Query_x.cuda()\n",
    "        Query_y = []\n",
    "        Query_y_count = []\n",
    "        centroid_per_class  = {}\n",
    "        class_label = {}\n",
    "        label_encoding = 0\n",
    "        for cls in K:\n",
    "            S_cls, Q_cls = self.random_sample_cls(datax, datay, Ns, Nq, cls)\n",
    "            centroid_per_class[cls] = self.get_centroid(S_cls, Nc)\n",
    "            class_label[cls] = label_encoding\n",
    "            label_encoding += 1\n",
    "            Query_x = torch.cat((Query_x, Q_cls), 0) # Joining all the query set together\n",
    "            Query_y += [cls]\n",
    "            Query_y_count += [Q_cls.shape[0]]\n",
    "        Query_y, Query_y_labels = self.get_query_y(Query_y, Query_y_count, class_label)\n",
    "        Query_x = self.get_query_x(Query_x, centroid_per_class, Query_y_labels)\n",
    "        return Query_x, Query_y\n",
    "    \n",
    "    def random_sample_cls(self, datax, datay, Ns, Nq, cls):\n",
    "        \"\"\"\n",
    "        Randomly samples Ns examples as support set and Nq as Query set\n",
    "        \"\"\"\n",
    "        data = datax[(datay == cls).nonzero()]\n",
    "        perm = torch.randperm(data.shape[0])\n",
    "        idx = perm[:Ns]\n",
    "        S_cls = data[idx]\n",
    "        idx = perm[Ns : Ns+Nq]\n",
    "        Q_cls = data[idx]\n",
    "        if self.gpu:\n",
    "            S_cls = S_cls.cuda()\n",
    "            Q_cls = Q_cls.cuda()\n",
    "        return S_cls, Q_cls\n",
    "    \n",
    "    def get_centroid(self, S_cls, Nc):\n",
    "        \"\"\"\n",
    "        Returns a centroid vector of support set for a class\n",
    "        \"\"\"\n",
    "        return torch.sum(self.f(S_cls), 0).unsqueeze(1).transpose(0,1) / Nc\n",
    "    \n",
    "    def get_query_y(self, Qy, Qyc, class_label):\n",
    "        \"\"\"\n",
    "        Returns labeled representation of classes of Query set and a list of labels.\n",
    "        \"\"\"\n",
    "        labels = []\n",
    "        m = len(Qy)\n",
    "        for i in range(m):\n",
    "            labels += [Qy[i]] * Qyc[i]\n",
    "        labels = np.array(labels).reshape(len(labels), 1)\n",
    "        label_encoder = LabelEncoder()\n",
    "        Query_y = torch.Tensor(label_encoder.fit_transform(labels).astype(int)).long()\n",
    "        if self.gpu:\n",
    "            Query_y = Query_y.cuda()\n",
    "        Query_y_labels = np.unique(labels)\n",
    "        return Query_y, Query_y_labels\n",
    "    \n",
    "    def get_centroid_matrix(self, centroid_per_class, Query_y_labels):\n",
    "        \"\"\"\n",
    "        Returns the centroid matrix where each column is a centroid of a class.\n",
    "        \"\"\"\n",
    "        centroid_matrix = torch.Tensor()\n",
    "        if(self.gpu):\n",
    "            centroid_matrix = centroid_matrix.cuda()\n",
    "        for label in Query_y_labels:\n",
    "            centroid_matrix = torch.cat((centroid_matrix, centroid_per_class[label]))\n",
    "        if self.gpu:\n",
    "            centroid_matrix = centroid_matrix.cuda()\n",
    "        return centroid_matrix\n",
    "    \n",
    "    def get_query_x(self, Query_x, centroid_per_class, Query_y_labels):\n",
    "        \"\"\"\n",
    "        Returns distance matrix from each Query image to each centroid.\n",
    "        \"\"\"\n",
    "        centroid_matrix = self.get_centroid_matrix(centroid_per_class, Query_y_labels)\n",
    "        Query_x = self.f(Query_x)\n",
    "        m = Query_x.size(0)\n",
    "        n = centroid_matrix.size(0)\n",
    "        # The below expressions expand both the matrices such that they become compatible to each other in order to caclulate L2 distance.\n",
    "        centroid_matrix = centroid_matrix.expand(m, centroid_matrix.size(0), centroid_matrix.size(1)) # Expanding centroid matrix to \"m\".\n",
    "        Query_matrix = Query_x.expand(n, Query_x.size(0), Query_x.size(1)).transpose(0,1) # Expanding Query matrix \"n\" times\n",
    "        Qx = torch.pairwise_distance(centroid_matrix.transpose(1,2), Query_matrix.transpose(1,2))\n",
    "        return Qx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "protonet = PrototypicalNet(use_gpu=use_gpu)\n",
    "optimizer = optim.SGD(protonet.parameters(), lr = 0.01, momentum=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(datax, datay, Ns,Nc, Nq):\n",
    "    optimizer.zero_grad()\n",
    "    Qx, Qy= protonet(datax, datay, Ns, Nc, Nq, np.unique(datay))\n",
    "    pred = torch.log_softmax(Qx, dim=-1)\n",
    "    loss = F.nll_loss(pred, Qy)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    acc = torch.mean((torch.argmax(pred, 1) == Qy).float())\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episode = 16000\n",
    "frame_size = 1000\n",
    "trainx = trainx.permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Number: 1 Frame Loss:  3.7078134765625 Frame Accuracy: 3.666987991333008\n",
      "Frame Number: 2 Frame Loss:  3.426573974609375 Frame Accuracy: 3.331317901611328\n",
      "Frame Number: 3 Frame Loss:  3.425421875 Frame Accuracy: 3.332318115234375\n",
      "Frame Number: 4 Frame Loss:  3.413877197265625 Frame Accuracy: 3.343653106689453\n",
      "Frame Number: 5 Frame Loss:  3.268108154296875 Frame Accuracy: 7.257671356201172\n",
      "Frame Number: 6 Frame Loss:  2.513345458984375 Frame Accuracy: 22.11765899658203\n",
      "Frame Number: 7 Frame Loss:  2.0368848876953125 Frame Accuracy: 37.47901611328125\n",
      "Frame Number: 8 Frame Loss:  1.56253173828125 Frame Accuracy: 59.7263916015625\n",
      "Frame Number: 9 Frame Loss:  1.1461754150390624 Frame Accuracy: 74.67138671875\n",
      "Frame Number: 10 Frame Loss:  0.894443115234375 Frame Accuracy: 81.41029052734375\n",
      "Frame Number: 11 Frame Loss:  0.715812255859375 Frame Accuracy: 86.08194580078126\n",
      "Frame Number: 12 Frame Loss:  0.5974201049804687 Frame Accuracy: 88.53203125\n",
      "Frame Number: 13 Frame Loss:  0.514778564453125 Frame Accuracy: 90.51575927734375\n",
      "Frame Number: 14 Frame Loss:  0.448422607421875 Frame Accuracy: 92.00136108398438\n",
      "Frame Number: 15 Frame Loss:  0.39060382080078127 Frame Accuracy: 93.32206420898437\n",
      "Frame Number: 16 Frame Loss:  0.35002841186523437 Frame Accuracy: 94.11031494140624\n"
     ]
    }
   ],
   "source": [
    "frame_loss = 0\n",
    "frame_acc = 0\n",
    "for i in range(num_episode):\n",
    "    loss, acc = train_step(trainx, trainy, 5, 60, 5)\n",
    "    frame_loss += loss.data\n",
    "    frame_acc += acc.data\n",
    "    if( (i+1) % frame_size == 0):\n",
    "        print(\"Frame Number:\", ((i+1) // frame_size), 'Frame Loss: ', frame_loss.data.cpu().numpy().tolist()/ frame_size, 'Frame Accuracy:', (frame_acc.data.cpu().numpy().tolist() * 100) / frame_size)\n",
    "        frame_loss = 0\n",
    "        frame_acc = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(datax, datay, Ns,Nc, Nq):\n",
    "    Qx, Qy= protonet(datax, datay, Ns, Nc, Nq, np.unique(datay))\n",
    "    pred = torch.log_softmax(Qx, dim=-1)\n",
    "    loss = F.nll_loss(pred, Qy)\n",
    "    acc = torch.mean((torch.argmax(pred, 1) == Qy).float())\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_episode = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss = 0\n",
    "avg_acc = 0\n",
    "for _ in range(num_test_episode):\n",
    "    loss, acc = test_step(testx, testy, 5, 60, 15)\n",
    "    avg_loss += loss.data\n",
    "    avg_acc += acc.data\n",
    "print('Avg Loss: ', avg_loss.data.cpu().numpy().tolist() / num_test_episode , 'Avg Accuracy:', (avg_acc.data.cpu().numpy().tolist() * 100) / num_test_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
